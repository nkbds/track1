{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Data Preparation\n",
    "\n",
    "### Steve Johnson and Lisiane Pruinelli\n",
    "\n",
    "#### 2018 Nursing Knowledge: Big Data Science Pre-Conference\n",
    "\n",
    "#### 6/13/18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QDvLFJcIxaah",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1.0 Setup\n",
    "\n",
    "Ensure that your Jupyter environment is setup correctly and import all of the data science libraries that we will need.  If some modules are missing, we will attempt to install the library but it is usually a better practice to install it in your environment directly.\n",
    "\n",
    "Also, if the data is missing, we will attempt to download it (from github) and put it in the \"/data\" subdirectory of your current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ZMOIsxe_NguU",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mplot\n",
    "%matplotlib inline\n",
    "import IPython\n",
    "from IPython.core.display import HTML\n",
    "from IPython.core.debugger import set_trace\n",
    "from distutils.version import StrictVersion\n",
    "print(\"numpy version:  %s\" % np.__version__)\n",
    "print(\"pandas version:  %s\" % pd.__version__)\n",
    "print(\"matplotlib version:  %s\" % mplot.__version__)\n",
    "print(\"IPython version:  %s\" % IPython.__version__)\n",
    "print(\"seaborn version:  %s\" % sns.__version__)\n",
    "\n",
    "if StrictVersion(np.__version__) >= StrictVersion('1.13.0') and \\\n",
    "   StrictVersion(pd.__version__) >= StrictVersion('0.20.0') and \\\n",
    "   StrictVersion(mplot.__version__) >= StrictVersion('2.0.0') and \\\n",
    "   StrictVersion(IPython.__version__) >= StrictVersion('5.5.0') and \\\n",
    "   StrictVersion(sns.__version__) >= StrictVersion('0.7.0'):\n",
    "    print('\\nCongratulations, your environment is setup correctly!')\n",
    "else:\n",
    "    print('\\nEnvironment is NOT setup correctly!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AVqO021euWsf",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Try to install the Excel reader library (its not pre-installed on Colab)\n",
    "try:\n",
    "    import xlrd\n",
    "    print('The Excel library is installed.')\n",
    "except ImportError:\n",
    "    print('Installing the Excel library')\n",
    "    !pip install xlrd\n",
    "    import xlrd\n",
    "# Try to install the Bokeh library (its not pre-installed on Colab)\n",
    "try:\n",
    "    import bokeh\n",
    "    print('The Bokeh library is installed.')\n",
    "except ImportError:\n",
    "    print('Installing the Bokeh library')\n",
    "    !pip install bokeh\n",
    "    import bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jWSv1aAZNgua",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1 Check data directory\n",
    "\n",
    "See if the data exists.  If not, try to download it from github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EqZAggVouWsk",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Find the data directory and download data if it is missing\n",
    "\n",
    "import os, shutil\n",
    "cwd = os.getcwd()\n",
    "datadir = cwd + '/data_oh'\n",
    "\n",
    "print('Data directory is: {}'.format(datadir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7k3ztEe_Nlvs",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# See if the data exists.  If not, try to download it from github.\n",
    "if not os.path.exists(datadir+'/patients.csv'):\n",
    "    print(\"Data directory doesn't exist!\")\n",
    "    print(\"Checking out the data from github...\")\n",
    "\n",
    "    !git clone https://github.com/nkbds/track1\n",
    "        \n",
    "    # Move the checked-out files into the /data directory\n",
    "    files = os.listdir('track1')\n",
    "    for f in files:\n",
    "        try:\n",
    "            shutil.move('track1/'+f,'.')\n",
    "        except:\n",
    "            print(\"Unable to move: \",f)\n",
    "            \n",
    "    try:\n",
    "        shutil.rmtree('track1')  # Remove the version control (git) information\n",
    "    except:\n",
    "        pass  # Ignore errors.  On Windows, this sometimes fails and leaves the .git directory\n",
    "print('Data directory contains:\\n',os.listdir(datadir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KZA3W-hhxkpV",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2.0 Read in the data\n",
    "\n",
    "Now that we have all the libraries installed and the data is available, lets try to read it into Pandas DataFrames.  \n",
    "\n",
    "The first thing we will do is define a Data Dictionary (dd) that describes our expectations for the data.  It includes data types for the columns as well is information about whether the column is required or optional.  The data is read into a dictionary of Dataframes (data) and also assigned to  variables (patients, encounters, etc) for convenience.\n",
    "\n",
    "We will convert dates and other fields to the proper format when later when we do data preparation.\n",
    "\n",
    "The dataset is synthetic data generated by the Synthea project (https://github.com/synthetichealth/synthea).  Synthea creates realistic (but not real) EHR-like data that we can use for demonstrating the techniques of data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "U3ymTsiKuWsn",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "dd = {}\n",
    "\n",
    "dd['patients'] = {'pat_id':     {'type': np.str, 'required':True},  \n",
    "                  'birth_date': {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                  'death_date': {'type': np.datetime64, 'format': '%Y-%m-%d' }, \n",
    "                  'ssn':        {'type': np.str},\n",
    "                  'drivers':    {'type': np.str},\n",
    "                  'passport':   {'type': np.str},\n",
    "                  'prefix':     {'type': np.str},\n",
    "                  'first':      {'type': np.str, 'required':True},\n",
    "                  'last':       {'type': np.str, 'required':True},\n",
    "                  'suffix':     {'type': np.str},\n",
    "                  'maiden':     {'type': np.str},\n",
    "                  'marital':    {'type': np.str},\n",
    "                  'race':       {'type': np.str},\n",
    "                  'ethnicity':  {'type': np.str},\n",
    "                  'gender':     {'type': np.str, 'required':True},\n",
    "                  'birthplace': {'type': np.str},\n",
    "                  'address':    {'type': np.str, 'required':True},\n",
    "                  'prior_opioid_abuse_diag': {'type': np.int}\n",
    "                  }\n",
    "dd['encounters'] = {'enc_id':                 {'type': np.str, 'required':True}, \n",
    "                    'enc_date':               {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                    'enc_pat_id':             {'type': np.str, 'required':True},\n",
    "                    'enc_code':               {'type': np.str, 'required':True},\n",
    "                    'enc_description':        {'type': np.str, 'required':True},\n",
    "                    'enc_reason_code':        {'type': np.str},\n",
    "                    'enc_reason_description': {'type': np.str}\n",
    "                   }\n",
    "dd['observations'] = {'obs_date':        {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                      'obs_pat_id':      {'type': np.str, 'required':True},\n",
    "                      'obs_enc_id':      {'type': np.str, 'required':True},\n",
    "                      'obs_code':        {'type': np.str, 'required':True},\n",
    "                      'obs_description': {'type': np.str, 'required':True},\n",
    "                      'obs_value':       {'type': np.str},\n",
    "                      'obs_units':       {'type': np.str}\n",
    "                     }\n",
    "dd['medications'] = {'med_start_date':         {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                     'med_stop_date':          {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':False},\n",
    "                     'med_pat_id':             {'type': np.str, 'required':True},\n",
    "                     'med_enc_id':             {'type': np.str, 'required':True},\n",
    "                     'med_code':               {'type': np.str, 'required':True},\n",
    "                     'med_description':        {'type': np.str, 'required':True},\n",
    "                     'med_reason_code':        {'type': np.str},\n",
    "                     'med_reason_description': {'type': np.str},\n",
    "                     'med_days_supply':        {'type': np.int}\n",
    "                     }\n",
    "dd['conditions'] =  {'cond_start_date':         {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':True},\n",
    "                     'cond_stop_date':          {'type': np.datetime64, 'format': '%Y-%m-%d', 'required':False},\n",
    "                     'cond_pat_id':             {'type': np.str, 'required':True},\n",
    "                     'cond_enc_id':             {'type': np.str, 'required':True},\n",
    "                     'cond_code':               {'type': np.str, 'required':True},\n",
    "                     'cond_description':        {'type': np.str, 'required':True}\n",
    "                     }\n",
    "\n",
    "\n",
    "# Display the data dictionary\n",
    "# Use HTML to make it look a little nicer\n",
    "\n",
    "for name, tbl_dd in dd.items():\n",
    "    display(HTML('<h2>{}</h2>'.format(name)))\n",
    "    display(pd.DataFrame(tbl_dd).fillna('').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "n3-p3h8lP7jR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each of the file defintions in our data dictionary\n",
    "data = {}\n",
    "for f in dd:\n",
    "    m = dd[f]\n",
    "    col_names = list(m.keys())\n",
    "    data[f] = pd.read_csv(datadir + '/{}.csv'.format(f), dtype=str, index_col=False, header=0, \\\n",
    "                          names=col_names, keep_default_na=False)\n",
    "\n",
    "# Assign data to local variables for convenience\n",
    "patients = data['patients']\n",
    "encounters = data['encounters']\n",
    "observations = data['observations']\n",
    "medications = data['medications']\n",
    "conditions = data['conditions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqtssqpRNgun",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1 Load the list of opioid medications\n",
    "\n",
    "It will be important to know which of the medications that are prescribed are considered opioids.  The UMLS VSAC maintains value set lists of which medications are considered opioids.  You can download the current list by going to https://vsac.nlm.nih.gov/ and searching for opioid value sets.  We have downloaded the list called \"All prescribable opioids used for pain control including Inactive Medications\" (oid 1.3.6.1.4.1.6997.4.1.2.234.999.3.2) into the data directory.  We will read the Excel file and pull out the codes from the second sheet in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6ygbd4wpNguo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Get Opioid code list from VSAC\n",
    "# oid 1.3.6.1.4.1.6997.4.1.2.234.999.3.2\n",
    "xl = pd.ExcelFile(datadir + '/AllPrescribableOpioidsUsedForPainControlIncludingInactiveMedications.xlsx')\n",
    "df = xl.parse(\"Code List\", skiprows=12)\n",
    "display(df.head(10))\n",
    "opioids_rxnorm = list(df['Code'].astype(np.str))  # Make sure the codes are treated as strings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwLnaiLiLjba",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3.0 Exploratory Data Analysis - Part 1\n",
    "\n",
    "Start by looking at the data to see what types of values are in each variables, the relationships and get a feel for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49JYp6fJNgur",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3.1 Start by displaying the data as DataFrames\n",
    "\n",
    "Displaying the first few rows of the data is a good way to look for obvious issues before working with the data in more detail.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "LvwqJrjoNgur",
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Loop through each of the file defintions in our data dictionary\n",
    "for f in dd:\n",
    "    m = dd[f]\n",
    "    display(HTML('<h3>{}, {} records</h3>'.format(f,len(data[f]))))\n",
    "    display(data[f].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# You can also display the last few rows using the .tail() function.\n",
    "patients.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2 Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Oxb4DG_nMDwv",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Look at the categorical variables\n",
    "\n",
    "sns.countplot(x='race', data=patients)\n",
    "plt.title('Race')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='obs_code',data=observations)\n",
    "plt.title('Observation Codes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# The observations are hard to read, lets try a bar plot\n",
    "c = observations['obs_description'].value_counts(ascending=True)\n",
    "fig = plt.figure(figsize=(8,24))\n",
    "c.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3 Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can get statistics for the continuous variables using the .describe() function\n",
    "patients.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XOOgSrclNguy",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# For continuous variables, we can graph the distribution\n",
    "\n",
    "w = observations[observations['obs_code']=='29463-7']   # Find all of the \"weight\" observations\n",
    "weights = w['obs_value'].astype(np.float).dropna()\n",
    "mean = np.mean(weights)\n",
    "print('Average weight: ',mean)\n",
    "\n",
    "# Plot the distribution\n",
    "sns.distplot(weights)\n",
    "plt.xlabel(\"WEIGHT (kg)\")\n",
    "plt.show()   # If you don't explicitly \"show\" the plot, Jupyter will automatically show the last plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Use Sort and Display\n",
    "\n",
    "This graph looks a little odd.  We have 2 peaks which are expected.  This corresponds to the average weight of a child vs average weight of an adult.  However, we have some values that seem to go all the way to 1400 Kg.  That doesn't seem right.  Let's take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Show the highest 20 weights\n",
    "print(weights.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Drop outliers\n",
    "\n",
    "It doesn't seem reasonable that someone weighs 1321.8 Kg.  So let's drop anything above 500 Kg.  We will use the Pandas Boolean Indexing to create a filter.  You can specify an arbitrary condition which is applied to each row in the DataFrame and only returns those rows that satisfy the conditional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "weights = weights[weights <= 500]\n",
    "print(weights.sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's re-plot the distribution\n",
    "sns.distplot(weights)\n",
    "plt.xlabel(\"WEIGHT (kg)\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7lz_KGneNgu0",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# As an Exercise, graph the Height of patients\n",
    "\n",
    "# Height LOINC code is 8302-2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-xiAaMhNgu2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4.0 Data Preparation\n",
    "\n",
    "Now that we know a little about our data, we can begin to prepare it for analysis.  We need to:\n",
    "1. Find data that is not formatted correctly\n",
    "2. Deal with missing data\n",
    "\n",
    "In all of these cases, we will have to decide what to do with the bad data.  We can:\n",
    "1. Delete the data\n",
    "2. Impute a reasonable value for the missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-xiAaMhNgu2",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 Data Quality Checks\n",
    "\n",
    "Start by running a few data quality checks against all of the data.  For this workshop, we will only look at missing data or incorrectly formatted data but with a real data science project you would also want to check that the relationships between all of the data elements makes sense.  For example, you'd ensure that the `birth_date` is less than today.\n",
    "\n",
    "The functions below attempt to convert the data (which we read in as simple strings) to the data format that we defined for each variable.  That's how we will tell if it is in the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Dn9X4BCjNgu8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Find data that is not formatted correctly\n",
    "\n",
    "def parse_date(dt,fmt):\n",
    "    if type(dt) == str and (dt == ''):\n",
    "        return dt\n",
    "    try:\n",
    "        return pd.to_datetime(dt,format=fmt)\n",
    "    except:\n",
    "        return np.datetime64('NaT')\n",
    "\n",
    "def parse_int(num):\n",
    "    if type(num) == str and (num == ''):\n",
    "        return num\n",
    "    try:\n",
    "        return int(num)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Loop through our Data Dictionary\n",
    "for name, tbl_dd in dd.items():\n",
    "    display(HTML('<h2>{}</h2>'.format(name)))\n",
    "    d = data[name]\n",
    "    for field_name, field in tbl_dd.items():\n",
    "        col = d[field_name]\n",
    "        field['DQ'] = {}\n",
    "        field['DQ']['missing'] = len(np.where(col == '')[0])\n",
    "\n",
    "        if field['type'] == np.datetime64:\n",
    "            if 'format' in field:\n",
    "                fmt = field['format']\n",
    "            else:\n",
    "                fmt = '%Y-%m-%d'   # Default date format if not specified\n",
    "                \n",
    "            d[field_name] = col.apply(lambda x: parse_date(x,fmt))\n",
    "            field['DQ']['format_errors'] = col.isnull().sum()\n",
    "        elif field['type'] == np.int:\n",
    "            d[field_name] = col.apply(lambda x: parse_int(x))\n",
    "            field['DQ']['format_errors'] = col.isnull().sum()\n",
    "        elif field['type'] == np.str:\n",
    "            pass # Everything is valid syntax\n",
    "            field['DQ']['format_errors'] = 0\n",
    "            \n",
    "    # Show the Data Quality information\n",
    "    display(pd.DataFrame(dd[name]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Drop unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's remove some of the data that we won't need to use for the workshop\n",
    "# It will make some of the screens easier to read\n",
    "# Put it in a try block in case we've already dropped the columns\n",
    "try:\n",
    "    patients.drop(['maiden','passport','drivers','prefix','suffix','ssn','first','last'],axis=1,inplace=True)\n",
    "except:\n",
    "    pass\n",
    "display(patients.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.3 Remove rows with missing data\n",
    "\n",
    "For this workshop, we will only deal with missing data by dropping it.  If a row has missing or bad formatted data and the field is required, we will drop the entire row.\n",
    "\n",
    "An alternative is to try to fix the data by imputing a reasonable value for it, such as the column .mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IWwIx3NYNgvF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# The .isnull() functions are used to find bad data\n",
    "# The .any() function returns the columns that contain any True values\n",
    "\n",
    "display(patients.isnull().head(5))\n",
    "display(patients.isnull().any())\n",
    "\n",
    "# Let's get a list of all of the columns with some missing data \n",
    "missing_cols=patients.columns[patients.isnull().any()]\n",
    "print(missing_cols)\n",
    "\n",
    "# We can see how many cells have missing data for each column\n",
    "patients[missing_cols].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Drop missing or incorrectly formatted data for the required patient data fields\n",
    "\n",
    "# Get the row numbers (index) of each of the rows with missing data\n",
    "missing = patients[patients.isnull().any(axis=1)].index\n",
    "print(\"Missing = \",missing)\n",
    "print('Before patients shape = ',patients.shape)\n",
    "patients.drop(missing,inplace=True)\n",
    "\n",
    "# Make sure the rows are gone\n",
    "missing = patients[patients.isnull().any(axis=1)].index\n",
    "print(\"Missing = \",missing)\n",
    "print('After patients shape = ',patients.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVVDeJqpMSK6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.4 Transform the Data\n",
    "\n",
    "Use the power of Pandas Dataframes to transform the data.  Add new columns as calculations from existing columns, join the data together and get it into the format you need for analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Mu-qPMysNgvP",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Create the working dataframe\n",
    "\n",
    "df = patients\n",
    "df['age'] = round((pd.Timestamp.today() - pd.to_datetime(patients['birth_date'])).dt.days/365)\n",
    "df['adult'] = np.where(df['age'] >= 18, 1, 0)\n",
    "\n",
    "# Determine which patients have ever overdosed\n",
    "# Use a set to eliminate duplicates\n",
    "patients_that_overdosed = set(encounters[encounters['enc_reason_code']=='55680006']['enc_pat_id'])  # Overdose\n",
    "df['overdose'] = np.where(df['pat_id'].isin(patients_that_overdosed), 1, 0)\n",
    "\n",
    "# Determine which patients were ever prescribed opioids\n",
    "patients_prescribed_opioids = set(medications[medications['med_code'].isin(opioids_rxnorm)]['med_pat_id'])  # Opioids\n",
    "df['prescribed_opioids'] = np.where(df['pat_id'].isin(patients_prescribed_opioids), 1, 0)\n",
    "\n",
    "print('Num patients prescribed opioids = {}, Num overdoses = {}'\n",
    "         .format(len(patients_prescribed_opioids),len(patients_that_overdosed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Determine which patients have died from an overdose\n",
    "# Uses binary indexing\n",
    "obs = observations[(observations['obs_code'] == '69453-9') &   # Death\n",
    "                                (observations['obs_value'].str.contains('overdose'))]\n",
    "print('Example of an overdose death observation:')\n",
    "display(pd.DataFrame(obs.iloc[0,:]))\n",
    "patients_overdose_deaths = set(obs['obs_pat_id'])\n",
    "print('Number of overdose deaths = {}'.format(len(patients_overdose_deaths)))\n",
    "print('Here are the overdose deaths:')\n",
    "display(df[df['pat_id'].isin(patients_overdose_deaths)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXdxuyM5MeIG",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.5 Compute the days_supply variable\n",
    "\n",
    "We want to compute how many days supply of a medication a patient was prescribed at discharge.  The approach we will use is that for each encounter, we will find all of the medications associated with the encounter.  We will look for medicates that are opioids and find the largest days supply for that encounter and store the result in the 'opioid_discharge_days_supply' column.\n",
    "\n",
    "This is most easily accomlished using a function that defines the logic and the \".apply\" DataFrame function the will iterate over each row in a DataFrame, call the function and store the result back in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HF7nIZwfNgvS",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the function that will perform to logic of compute the discharge opioid days supply\n",
    "\n",
    "def get_days_supply(pat_id):\n",
    "    enc_meds = medications[medications['med_pat_id'] == pat_id]\n",
    "    enc_opioid_meds = enc_meds[enc_meds['med_code'].isin(opioids_rxnorm)]\n",
    "    max = 0\n",
    "    if len(enc_opioid_meds) > 0:\n",
    "        try:\n",
    "            max = int(enc_opioid_meds['med_days_supply'].max())\n",
    "        except ValueError:\n",
    "            max = 0\n",
    "    return int(max)\n",
    "\n",
    "# Apply the function to each row (Note: this can take a little while to finish)\n",
    "df['opioid_discharge_days_supply'] = df.apply(lambda x: get_days_supply(x['pat_id']), axis=1)\n",
    "\n",
    "# Display the first 5 entries that have a non-zero days supply, just to check our logic\n",
    "df[df['opioid_discharge_days_supply'] > 0].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.6 Save our Clean Data\n",
    "\n",
    "It is a good practice to save your clean data so that you don't have to keep re-cleaning it everytime you want to use it.  Pandas (and Python) provides a function to save a variable in a special format that can be easily recreated later.  This is called 'pickling' in Python.  So we will save our cleaned DataFrame, df, to be used by subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle the data \n",
    "df.to_pickle(datadir+'/data_cleaned_oh.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2An5P7D0NgvU",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5.0 Explore the Data - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ygRWbg6_QHur",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.1 Outcome variable\n",
    "\n",
    "Now that we have created some new variables, lets take a look at how the outcome variable is associated with our predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8w6XYA9eNgva",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# See who overdosed from prescribed opioids by computing the intersection\n",
    "\n",
    "overlap = patients_that_overdosed.intersection(patients_prescribed_opioids)\n",
    "\n",
    "print('Num that overdose = {}, Num that were prescribed opioids = {}, overlap = {}'.format(\\\n",
    "    len(patients_that_overdosed),len(patients_prescribed_opioids),len(overlap)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwbdILHlNgvb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How many patients overdosed?\n",
    "\n",
    "Since we store 'overdose' as a 0 or 1, we can just use the mean function to compute what percent of the population overdosed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "D6W9vKMeNgvb",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "overdose = df[df['pat_id'].isin(patients_prescribed_opioids)]\n",
    "display(overdose['overdose'].value_counts())\n",
    "print('Percent that overdosed: {0:.2f}%'.format(overdose['overdose'].mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2 Crosstabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M2AvZvFJNgvh",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# What was the mean number of days_supply for patients that overdosed and were prescribed opioids?\n",
    "\n",
    "ct = pd.crosstab(df['prescribed_opioids'],df['opioid_discharge_days_supply'])\n",
    "display(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "M2AvZvFJNgvh",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This plots the values in row 1 of the the ct DataFrame\n",
    "ct.iloc[1][1:].plot()\n",
    "plt.title('Days Supply for Opioid Patients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multiple graphs using Facetgrid\n",
    "\n",
    "We can also see multiple graphs at the same time using the Seaborn Facetgrid function.  It lets you see the same graph split by up to 2 variables.  For example, we can look at how overdose is related to age and gender and whether the patient was ever prescribed opioids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "p = sns.FacetGrid(df, row='overdose', col='gender', hue='prescribed_opioids', sharey=False)\n",
    "p.map(plt.hist, 'age')\n",
    "p.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DQTjt_xaNgvj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.3 Graph the patient variables against the outcome\n",
    "\n",
    "Let's see if gender, race and age are associated with the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v6y5oqBmNgvk",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(patients['gender'],patients['overdose']).plot(kind='bar')\n",
    "plt.title('Overdose by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "6Ii3ZGpENgvo",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(patients['race'],patients['overdose']).plot(kind='bar')\n",
    "plt.title('Overdose by Race')\n",
    "plt.xlabel('Race')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R__EWwiLNgvp",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have a pretty uniform distribution of ages in the patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "itxkiNCNNgvp",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Histograms are easy to create\n",
    "patients['age'].hist()\n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qcaI-FaONgvs",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.4 Grouping by a variable\n",
    "\n",
    "We often want to group related rows together and then count the number rows of each type or find the mean of a variable for each row type.\n",
    "\n",
    "For example, lets count how many encounters each patient has over the timeframe of the data.  We will use the `groupby` function to group on a set of variables.  The operation returns a `groupby` object which doesn't actually group the data but instead acts like a set of instructions telling the DataFrame how to group itself.  We need to apply another function, such as size(), mean() or sum(), to the groups to yield a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "EAW0QqbkLrJh",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# How many encounters does each patient have?\n",
    "\n",
    "encs = encounters.groupby(['enc_pat_id']).size()\n",
    "\n",
    "# We can store that information directly into the patients DataFrame since `encs` is indexed by the pat_id\n",
    "patients = patients.set_index('pat_id')\n",
    "patients['num_encounters'] = encs\n",
    "patients = patients.reset_index()\n",
    "\n",
    "# Visualize the number of encounters as a patient ages, use color to highlight the gender difference\n",
    "sns.lmplot(data=patients,x='age',y='num_encounters',hue='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "IZWAMdv1Ngvd",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We can also apply a function to the groups\n",
    "df.groupby('overdose').mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1X5aAmRPNgvu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.5 For those that overdose, what is the days_supply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_g69wExxNgvu",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "display(df[df['overdose']==1].mean())\n",
    "display(df[df['prescribed_opioids']==1].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-iNFJ0dNgvx",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.6 What are the primary reasons for visit for patients that ever overdosed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "5KOtf0EZNgvx",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "encounters[encounters['enc_pat_id'].isin(patients_that_overdosed)]['enc_reason_description'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.7 Who overdosed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "dIhLzt0XNgv7",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Who were the patients that overdosed?\n",
    "\n",
    "pt = df[df['pat_id'].isin(patients_that_overdosed)]\n",
    "\n",
    "pt.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1l2tXR5hNgv3",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.8 Get an idea of how a patient progresses through their healthcare\n",
    "\n",
    "When exploring the data, it helps to visualize what is happening across time.  You can create small functions within the Jupyter notebook and reuse them further down in the notebook.  \n",
    "\n",
    "In this case, we are looping through the encounter data for a patient and print all of the medications and labs (observations) that are associated with the patient.  The function `display_trajectory` is passed the id for a patient and then prints the information.  We can use this later to further examine data or debug things we don't understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kNlJlgaCY-O2",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def display_trajectory(df,pt_id):\n",
    "    pt = patients[patients['pat_id']==pt_id]\n",
    "\n",
    "    display(pt)\n",
    "    encs = encounters[encounters.enc_pat_id == pt_id]\n",
    "    #print(encs.shape)\n",
    "    for i, e in encs.iterrows():\n",
    "        #dt = df[df['pat_id']==e['enc_pat_id']].iloc[0]\n",
    "        print('  {:%Y-%m-%d}: {} ({}) ({})'.format(e['enc_date'], e['enc_description'], \\\n",
    "                         e['enc_code'], e['enc_reason_description']))\n",
    "        meds = medications[medications['med_enc_id'] == e['enc_id']]\n",
    "        for j, m in meds.iterrows():\n",
    "            print('     MED: {:%Y-%m-%d}: {} ({}) days_supply={}'.format(m['med_start_date'],  \\\n",
    "                                            m['med_description'], m['med_code'], m['med_days_supply']))\n",
    "        labs = observations[observations['obs_enc_id'] == e['enc_id']]\n",
    "        for k, l in labs.iterrows():\n",
    "            print('     LAB: {:%Y-%m-%d %H:%M}: {} ({}) {} {}'.format(l['obs_date'], l['obs_description'], l['obs_code'], l['obs_value'], l['obs_units']))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gF98rMhDNgv9",
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Display the trajectory of one of the overdose patients\n",
    "pt_id = list(patients_that_overdosed)[1]\n",
    "display_trajectory(df,pt_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.9 Geographic Mapping\n",
    "\n",
    "We can also easily visualize our data geographically.  All of our patients have addresses.  We can use a library called Bokeh and Google Maps API to quickly visualize where are patients come from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook, show, reset_output\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, Range1d, PanTool, WheelZoomTool\n",
    ")\n",
    "\n",
    "# Read in the Latitude/Longitude of the patients\n",
    "patlocations = pd.read_csv(datadir + '/patlocations.csv', dtype=str, index_col=False, header=0, keep_default_na=False)\n",
    "display(patlocations.head(5))\n",
    "\n",
    "reset_output()\n",
    "plot = GMapPlot(\n",
    "    x_range=Range1d(), y_range=Range1d(), \n",
    "    map_options=GMapOptions(lat=40, lng=-83, map_type=\"roadmap\", zoom=6)\n",
    ")\n",
    "plot.title.text = \"Patient Locations\"\n",
    "\n",
    "# For GMaps to function, Google requires you obtain and enable an API key:\n",
    "#\n",
    "#     https://developers.google.com/maps/documentation/javascript/get-api-key\n",
    "#\n",
    "# Replace the value below with your personal API key:\n",
    "plot.api_key = \"AIzaSyCfADVk_rJUwvypVHvSQZN8-TFr8jnvLmE\"\n",
    "\n",
    "circle = Circle(x=\"lng\", y=\"lat\", size=15, fill_color=\"green\", fill_alpha=1.0, line_color=None)\n",
    "src=ColumnDataSource(patlocations)\n",
    "plot.add_glyph(src, circle)\n",
    "\n",
    "plot.add_tools(PanTool(), WheelZoomTool())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Now lets show the plot, which is interactive\n",
    "output_notebook()\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Show where the patients that overdosed live\n",
    "\n",
    "We can use color to highlight patients in different categories.  For example, we can show the patients that overdosed in red to see if there is a pattern to where they live."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Add 2 new columns to the DataFrame to indicate which patients overdosed and what color should be displayed\n",
    "patlocations['overdosed'] = np.where(patlocations['pat_id'].isin(patients_that_overdosed), 1, 0)\n",
    "patlocations['color'] = np.where(patlocations['overdosed'], 'red', 'green')\n",
    "\n",
    "display(patlocations[patlocations['overdosed'] == 1].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Display the graph\n",
    "reset_output()\n",
    "\n",
    "plot2 = GMapPlot(\n",
    "    x_range=Range1d(), y_range=Range1d(), \n",
    "    map_options=GMapOptions(lat=40, lng=-83, map_type=\"roadmap\", zoom=6)\n",
    ")\n",
    "plot2.title.text = \"Patient Locations (Overdose)\"\n",
    "plot2.api_key = \"AIzaSyCfADVk_rJUwvypVHvSQZN8-TFr8jnvLmE\"\n",
    "circle = Circle(x=\"lng\", y=\"lat\", size=15, fill_color=\"color\", fill_alpha=1.0, line_color=None)\n",
    "src=ColumnDataSource(patlocations)\n",
    "plot2.add_glyph(src, circle)\n",
    "\n",
    "plot2.add_tools(PanTool(), WheelZoomTool())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Now show the graph\n",
    "output_notebook()\n",
    "show(plot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Workshop Survey\n",
    "\n",
    "We hope that you found this workshop useful.  We would like for you to give use feedback to improve the workshop by completing a very short survey that you can access at:\n",
    "\n",
    "https://docs.google.com/forms/d/e/1FAIpQLSct-waQrz7RhWxawmU1kgf7IwAYyONhwMNpgmGYpGJTpATBdA/viewform"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "NKBDS_Track1_Data_Prep.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "livereveal": {
   "footer": "NKBDS 2018 Pre-Conference",
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
